# Shutka V2: Ultra-Efficient TypeScript Coding Agent

Shutka is a state-of-the-art **VL-JEPA** (Vision-Language Joint Embedding Predictive Architecture) model specifically optimized for low-latency, high-precision TypeScript code assistance on local hardware.

## ğŸš€ Key Innovations (V2)

Shutka V2 incorporates cutting-edge architectural advancements to provide a premium coding experience:

- **VL-JEPA Paradigm**: Non-autoregressive representation learning using semantic patches rather than sequential token prediction.
- **RMSNorm**: Faster, hardware-efficient normalization (as used in Llama-3 and Mistral).
- **SwiGLU Activations**: Enhanced reasoning performance using Gated Linear Units.
- **Rotary Positional Embeddings (RoPE)**: Dynamic, relative positional information for superior code understanding and extrapolation.
- **BitLinear 1.58b**: Ternary weight quantization reducing memory usage by up to 16x.
- **Flash Linear Attention**: Scalable $O(N)$ complexity for long context windows.
- **Dynamic FAISS Memory (RAG)**: Mutable external memory bank with ID-based management (Add/Delete/Update).

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ models/
â”‚   â””â”€â”€ shutka.py             # Shutka V2 (RMSNorm, RoPE, SwiGLU, BitLinear)
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ trainer.py            # Phase-aware trainer with GPU optimizations
â”‚   â”œâ”€â”€ train_typescript.py   # PHASE 1: Syntax & Structure training script
â”‚   â”œâ”€â”€ train_real_data.py    # PHASE 2: Instruction-following training script
â”‚   â”œâ”€â”€ typescript_loader.py  # Rich semantic extractor (classes, types, etc.)
â”‚   â””â”€â”€ real_instruction_loader.py # Multi-source instruction streamer
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ eval.py               # Main evaluation entry point
â”‚   â”œâ”€â”€ evaluator.py          # Representation & Retrieval metrics
â”‚   â”œâ”€â”€ test_syntax.py        # Bun-powered TS syntax verification
â”‚   â”œâ”€â”€ test_programming.py   # Functional logic verification
â”‚   â”œâ”€â”€ test_algorithmic.py   # Complex algorithmic tests
â”‚   â””â”€â”€ test_suites/          # JSON definitions for all tests
â”œâ”€â”€ config.py                 # Unified hyperparameter management
â”œâ”€â”€ evaluate_shutka.py        # Wrapper for evaluation runs
â”œâ”€â”€ KAGGLE_GUIDE.md           # Cloud training blueprints
â””â”€â”€ README.md                 # Project documentation
```

## ğŸ› ï¸ Dynamic Memory Management

Shutka V2 features a mutable FAISS memory bank. You can manage the model's knowledge without retraining:

```python
from models.shutka import UltraEfficientTextJEPA

model = UltraEfficientTextJEPA()
bank = model.predictor.memory_bank

# 1. Add new knowledge
ids = bank.add_memory(new_embeddings, ["Updated API documentation..."])

# 2. Delete stale info
bank.delete_memory(ids)

# 3. Update existing entry
bank.update_memory(old_id, new_embeddings, "New implementation...")
```

## ğŸš€ Getting Started

### 1. Installation

## for CPU

```bash
# Optimized for Bun & Python 3.10+
pip install faiss-cpu datasets tiktoken torch numpy tqdm
```

## for GPU

```bash
# Optimized for Bun & Python 3.10+
pip install faiss-gpu datasets tiktoken torch numpy tqdm bitsandbytes
```

### 2. Recommended Training Sequence

To turn Shutka into a premium coding agent, we recommend a two-phase training approach:

#### Phase 1: Syntax (The Grammar)

Learn the syntax and structural patterns of TypeScript.

```bash
python training/train_typescript.py --max_samples 50000 --epochs 5
```

#### Phase 2: Instruction Following (The Agent)

Train the model to map natural language to code using real-world data.

```bash
python training/train_real_data.py --resume checkpoints/best_model.pt --epochs 10
```

### 3. Evaluation (Bun Optimized)

```bash
# Verify syntax and programming logic
python evaluation/eval.py --checkpoint checkpoints/best_model.pt
```

## ğŸ“Š Performance

Shutka V2 is designed to run on a **GTX 1050 (4GB)** or even purely on **CPUs** while maintaining high accuracy, achieving a ~2.0GB memory footprint in full training mode and <1GB during inference.

## ğŸ“„ References

- [VL-JEPA (Joint Embedding Predictive Architecture)](https://arxiv.org/abs/2512.10942)
- [RoPE (Rotary Positional Embeddings)](https://arxiv.org/abs/2104.09864)
- [Llama-3 Architecture (RMSNorm & SwiGLU)](https://ai.meta.com/blog/meta-llama-3/)
